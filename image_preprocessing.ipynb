{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerias Necesarias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import splitfolders\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detección de Imágenes Corruptas/No válidas**\n",
    "\n",
    "Esta sección revisa si existen imágenes dentro del dataset que no son válidas o que esten corruptas.\n",
    "Las que sean detectadas seran reemplazadas manualmente por otras imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_corrupted(image_path):\n",
    "    \"\"\"\n",
    "    Checks if an image file is corrupted by attempting to open and verify it.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the image is corrupted, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            img.verify()  # Verify does not decode the image, but ensures it's intact\n",
    "        return False  # Image is not corrupted\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print(f\"\\nCorrupted: {image_path} - {e}\")\n",
    "        return True  # Image is corrupted\n",
    "\n",
    "\n",
    "def check_images_in_folder(main_folder):\n",
    "    \"\"\"\n",
    "    Check for corrupted images in a given folder.\n",
    "\n",
    "    Args:\n",
    "        main_folder (str): The path to the main folder containing the images.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Prints the number of corrupted images found and their file paths, if any.\n",
    "    \"\"\"\n",
    "    corrupted_images = []\n",
    "    for root, _, files in os.walk(main_folder):\n",
    "        for file in files:\n",
    "            image_path = os.path.join(root, file)\n",
    "            if is_image_corrupted(image_path):\n",
    "                corrupted_images.append(image_path)\n",
    "\n",
    "    if corrupted_images:\n",
    "        print(f\"\\nFound {len(corrupted_images)} corrupted images.\")\n",
    "        for img in corrupted_images:\n",
    "            print(img)\n",
    "    else:\n",
    "        print(\"No corrupted images found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No corrupted images found.\n"
     ]
    }
   ],
   "source": [
    "# Check images in the 'dinosaurs' folder\n",
    "main_folder_path = 'dataset/dinosaurs'\n",
    "check_images_in_folder(main_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WEBP Image Convertion**\n",
    "\n",
    "Esta sección detecta y convierte archivos con extensión WEBP a formato PNG para que sean editables.\n",
    "Al convertirlas es posible hacer un corte manual de aquellas imágenes que lo requieran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_replace_webp_with_png(main_folder):\n",
    "    \"\"\"\n",
    "    Converts and replaces all WebP files in the specified folder with PNG files.\n",
    "\n",
    "    Args:\n",
    "        main_folder (str): The path to the main folder containing the WebP files.\n",
    "    \"\"\"\n",
    "    target_extension = '.webp'\n",
    "    replaced_count = 0  # Initialize the counter\n",
    "\n",
    "    for root, _, files in os.walk(main_folder):\n",
    "        for file in files:\n",
    "            file_lower = file.lower()\n",
    "            if file_lower.endswith(target_extension):\n",
    "                file_path = os.path.join(root, file)\n",
    "                png_path = os.path.splitext(file_path)[0] + '.png'\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img = img.convert('RGBA')  # Convert to a standard color mode\n",
    "                        img.save(png_path, 'PNG')\n",
    "                    os.remove(file_path)  # Remove the original WebP file\n",
    "                    replaced_count += 1  # Increment the counter\n",
    "                    print(f\"Converted and replaced: {file_path} to {png_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to convert {file_path}: {e}\")\n",
    "\n",
    "    # Print the total count of replaced files\n",
    "    print(f\"\\nTotal WebP files replaced: {replaced_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total WebP files replaced: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert and replace WebP files with PNG in the 'dinosaurs' folder\n",
    "main_folder_path = 'dinosaurs'\n",
    "convert_and_replace_webp_with_png(main_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Balance Verification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_by_format(folder_path):\n",
    "    \"\"\"\n",
    "    Counts the number of images in each subfolder of the given folder path, grouped by file format.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): The path to the folder containing subfolders with images.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the counts of images for each subfolder and file format.\n",
    "              The dictionary has the following structure:\n",
    "              {\n",
    "                  subfolder1: {\n",
    "                      file_extension1: count1,\n",
    "                      file_extension2: count2,\n",
    "                      ...\n",
    "                  },\n",
    "                  ...\n",
    "              }\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    for subfolder in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            counts[subfolder] = {}\n",
    "            for file in os.listdir(subfolder_path):\n",
    "                file_extension = os.path.splitext(file)[1].lower()\n",
    "                counts[subfolder][file_extension] = counts[subfolder].get(file_extension, 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Allosaurus:\n",
      "  .jpeg: 5\n",
      "  .jpg: 60\n",
      "  .png: 35\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Ankylosaurus:\n",
      "  .jpg: 53\n",
      "  .png: 45\n",
      "  .jpeg: 2\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Baryonyx:\n",
      "  .png: 40\n",
      "  .jpg: 56\n",
      "  .jpeg: 4\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Brachiosaurus:\n",
      "  .jpg: 69\n",
      "  .png: 29\n",
      "  .jpeg: 2\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Carnotaurus:\n",
      "  .jpg: 61\n",
      "  .png: 36\n",
      "  .jpeg: 3\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Corythosaurus:\n",
      "  .jpg: 64\n",
      "  .jpeg: 2\n",
      "  .png: 34\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Dilophosaurus:\n",
      "  .jpg: 62\n",
      "  .png: 35\n",
      "  .jpeg: 3\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Pachycephalosaurus:\n",
      "  .jpg: 66\n",
      "  .png: 30\n",
      "  .jpeg: 4\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Parasaurolophus:\n",
      "  .png: 31\n",
      "  .jpg: 67\n",
      "  .jpeg: 2\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Pteranodon:\n",
      "  .jpeg: 2\n",
      "  .jpg: 67\n",
      "  .png: 31\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Spinosaurus:\n",
      "  .jpg: 66\n",
      "  .png: 34\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Stegosaurus:\n",
      "  .jpg: 67\n",
      "  .png: 33\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Therizinosaurus:\n",
      "  .png: 33\n",
      "  .jpg: 62\n",
      "  .jpeg: 5\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Triceratops:\n",
      "  .jpg: 60\n",
      "  .png: 36\n",
      "  .jpeg: 4\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Tyrannosaurus:\n",
      "  .png: 39\n",
      "  .jpg: 60\n",
      "  .jpeg: 1\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Velociraptor:\n",
      "  .png: 33\n",
      "  .jpg: 64\n",
      "  .jpeg: 3\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n"
     ]
    }
   ],
   "source": [
    "# Count images by format in the 'dinosaurs' folder\n",
    "folder_path = 'dataset/dinosaurs'\n",
    "counts = count_images_by_format(folder_path)\n",
    "for subfolder, formats in counts.items():\n",
    "    print(f\"\\n{subfolder}:\")\n",
    "    for format, count in formats.items():\n",
    "        print(f\"  {format}: {count}\")\n",
    "    total = sum(formats.values())\n",
    "    if total == 100:\n",
    "        print(f\"Succes: All images are present. \\nTotal: {total} images\")\n",
    "    else:\n",
    "        print(f\"Error: {total} images counted, missing {100 - total} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image padding, resizing and conversion to BMP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(original_folder_path, output_folder_path, max_subfolders=None):\n",
    "    \"\"\"\n",
    "    Process images within subfolders of the specified folder by renaming, converting, padding to square,\n",
    "    and resizing to 100x100 pixels. The processed images will be stored in a new folder.\n",
    "\n",
    "    Args:\n",
    "        original_folder_path (str): Path to the original folder containing subfolders with images.\n",
    "        output_folder_path (str): Path to the output folder that will contain the processed images.\n",
    "        max_subfolders (int, optional): Maximum number of subfolders to process. If None, process all subfolders.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If any error occurs during the processing of images.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the output folder structure mirroring the original\n",
    "        if not os.path.exists(output_folder_path):\n",
    "            os.makedirs(output_folder_path)\n",
    "\n",
    "        # Delete the output folder if it already exists\n",
    "        else:\n",
    "            shutil.rmtree(output_folder_path)\n",
    "            os.makedirs(output_folder_path)\n",
    "\n",
    "        # Initialize the counter for processed subfolders\n",
    "        processed_subfolders = 0\n",
    "\n",
    "        # Process each subfolder in the original folder\n",
    "        for root, dirs, files in os.walk(original_folder_path):\n",
    "            if max_subfolders is not None and processed_subfolders >= max_subfolders:\n",
    "                break\n",
    "\n",
    "            rel_path = os.path.relpath(root, original_folder_path)\n",
    "            current_output_dir = os.path.join(output_folder_path, rel_path)\n",
    "            \n",
    "            if not os.path.exists(current_output_dir):\n",
    "                os.makedirs(current_output_dir)\n",
    "\n",
    "            if root != original_folder_path:\n",
    "                subfolder_name = os.path.basename(root)\n",
    "\n",
    "                print(f\"Processing folder: {subfolder_name}\")\n",
    "\n",
    "                # Process each image file in the subfolder\n",
    "                for index, file_name in enumerate(files):\n",
    "                    file_path = os.path.join(root, file_name)\n",
    "\n",
    "                    if os.path.isfile(file_path):\n",
    "                        try:\n",
    "                            # Open the image\n",
    "                            with Image.open(file_path) as img:\n",
    "\n",
    "                                # Replace transparency with white\n",
    "                                if img.mode in ('RGBA', 'LA'):\n",
    "                                    background = Image.new(img.mode[:-1], img.size, (255, 255, 255))\n",
    "                                    background.paste(img, img.split()[-1])\n",
    "                                    img = background\n",
    "                                elif img.mode == 'P':\n",
    "                                    img = img.convert('RGB')\n",
    "\n",
    "                                # Padding to make the image square\n",
    "                                width, height = img.size\n",
    "                                if width != height:\n",
    "                                    max_dim = max(width, height)\n",
    "                                    new_img = Image.new(\"RGB\", (max_dim, max_dim), (255, 255, 255))\n",
    "                                    new_img.paste(img, ((max_dim - width) // 2, (max_dim - height) // 2))\n",
    "                                    img = new_img\n",
    "\n",
    "                                # Resize to 100x100 pixels using LANCZOS (formerly ANTIALIAS)\n",
    "                                img = img.resize((100, 100), Image.Resampling.LANCZOS)\n",
    "\n",
    "                                # Rename the file according to the subfolder name and index\n",
    "                                new_file_name = f\"{subfolder_name}_{index}.bmp\"\n",
    "                                new_file_path = os.path.join(current_output_dir, new_file_name)\n",
    "\n",
    "                                # Save the converted image as .bmp\n",
    "                                img.save(new_file_path, format='BMP')\n",
    "\n",
    "                                print(f\"Processed: {new_file_name}\")\n",
    "\n",
    "                        except UnidentifiedImageError as e:\n",
    "                            raise Exception(f\"Error processing {file_name}: Unidentified image file. {e}\")\n",
    "                \n",
    "                print(f\"Finished processing folder: {subfolder_name}\\n\")\n",
    "                processed_subfolders += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred while processing images: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: Allosaurus\n",
      "Processed: Allosaurus_0.bmp\n",
      "Processed: Allosaurus_1.bmp\n",
      "Processed: Allosaurus_2.bmp\n",
      "Processed: Allosaurus_3.bmp\n",
      "Processed: Allosaurus_4.bmp\n",
      "Processed: Allosaurus_5.bmp\n",
      "Processed: Allosaurus_6.bmp\n",
      "Processed: Allosaurus_7.bmp\n",
      "Processed: Allosaurus_8.bmp\n",
      "Processed: Allosaurus_9.bmp\n",
      "Processed: Allosaurus_10.bmp\n",
      "Processed: Allosaurus_11.bmp\n",
      "Processed: Allosaurus_12.bmp\n",
      "Processed: Allosaurus_13.bmp\n",
      "Processed: Allosaurus_14.bmp\n",
      "Processed: Allosaurus_15.bmp\n",
      "Processed: Allosaurus_16.bmp\n",
      "Processed: Allosaurus_17.bmp\n",
      "Processed: Allosaurus_18.bmp\n",
      "Processed: Allosaurus_19.bmp\n",
      "Processed: Allosaurus_20.bmp\n",
      "Processed: Allosaurus_21.bmp\n",
      "Processed: Allosaurus_22.bmp\n",
      "Processed: Allosaurus_23.bmp\n",
      "Processed: Allosaurus_24.bmp\n",
      "Processed: Allosaurus_25.bmp\n",
      "Processed: Allosaurus_26.bmp\n",
      "Processed: Allosaurus_27.bmp\n",
      "Processed: Allosaurus_28.bmp\n",
      "Processed: Allosaurus_29.bmp\n",
      "Processed: Allosaurus_30.bmp\n",
      "Processed: Allosaurus_31.bmp\n",
      "Processed: Allosaurus_32.bmp\n",
      "Processed: Allosaurus_33.bmp\n",
      "Processed: Allosaurus_34.bmp\n",
      "Processed: Allosaurus_35.bmp\n",
      "Processed: Allosaurus_36.bmp\n",
      "Processed: Allosaurus_37.bmp\n",
      "Processed: Allosaurus_38.bmp\n",
      "Processed: Allosaurus_39.bmp\n",
      "Processed: Allosaurus_40.bmp\n",
      "Processed: Allosaurus_41.bmp\n",
      "Processed: Allosaurus_42.bmp\n",
      "Processed: Allosaurus_43.bmp\n",
      "Processed: Allosaurus_44.bmp\n",
      "Processed: Allosaurus_45.bmp\n",
      "Processed: Allosaurus_46.bmp\n",
      "Processed: Allosaurus_47.bmp\n",
      "Processed: Allosaurus_48.bmp\n",
      "Processed: Allosaurus_49.bmp\n",
      "Processed: Allosaurus_50.bmp\n",
      "Processed: Allosaurus_51.bmp\n",
      "Processed: Allosaurus_52.bmp\n",
      "Processed: Allosaurus_53.bmp\n",
      "Processed: Allosaurus_54.bmp\n",
      "Processed: Allosaurus_55.bmp\n",
      "Processed: Allosaurus_56.bmp\n",
      "Processed: Allosaurus_57.bmp\n",
      "Processed: Allosaurus_58.bmp\n",
      "Processed: Allosaurus_59.bmp\n",
      "Processed: Allosaurus_60.bmp\n",
      "Processed: Allosaurus_61.bmp\n",
      "Processed: Allosaurus_62.bmp\n",
      "Processed: Allosaurus_63.bmp\n",
      "Processed: Allosaurus_64.bmp\n",
      "Processed: Allosaurus_65.bmp\n",
      "Processed: Allosaurus_66.bmp\n",
      "Processed: Allosaurus_67.bmp\n",
      "Processed: Allosaurus_68.bmp\n",
      "Processed: Allosaurus_69.bmp\n",
      "Processed: Allosaurus_70.bmp\n",
      "Processed: Allosaurus_71.bmp\n",
      "Processed: Allosaurus_72.bmp\n",
      "Processed: Allosaurus_73.bmp\n",
      "Processed: Allosaurus_74.bmp\n",
      "Processed: Allosaurus_75.bmp\n",
      "Processed: Allosaurus_76.bmp\n",
      "Processed: Allosaurus_77.bmp\n",
      "Processed: Allosaurus_78.bmp\n",
      "Processed: Allosaurus_79.bmp\n",
      "Processed: Allosaurus_80.bmp\n",
      "Processed: Allosaurus_81.bmp\n",
      "Processed: Allosaurus_82.bmp\n",
      "Processed: Allosaurus_83.bmp\n",
      "Processed: Allosaurus_84.bmp\n",
      "Processed: Allosaurus_85.bmp\n",
      "Processed: Allosaurus_86.bmp\n",
      "Processed: Allosaurus_87.bmp\n",
      "Processed: Allosaurus_88.bmp\n",
      "Processed: Allosaurus_89.bmp\n",
      "Processed: Allosaurus_90.bmp\n",
      "Processed: Allosaurus_91.bmp\n",
      "Processed: Allosaurus_92.bmp\n",
      "Processed: Allosaurus_93.bmp\n",
      "Processed: Allosaurus_94.bmp\n",
      "Processed: Allosaurus_95.bmp\n",
      "Processed: Allosaurus_96.bmp\n",
      "Processed: Allosaurus_97.bmp\n",
      "Processed: Allosaurus_98.bmp\n",
      "Processed: Allosaurus_99.bmp\n",
      "Finished processing folder: Allosaurus\n",
      "\n",
      "Processing folder: Ankylosaurus\n",
      "Processed: Ankylosaurus_0.bmp\n",
      "Processed: Ankylosaurus_1.bmp\n",
      "Processed: Ankylosaurus_2.bmp\n",
      "Processed: Ankylosaurus_3.bmp\n",
      "Processed: Ankylosaurus_4.bmp\n",
      "Processed: Ankylosaurus_5.bmp\n",
      "Processed: Ankylosaurus_6.bmp\n",
      "Processed: Ankylosaurus_7.bmp\n",
      "Processed: Ankylosaurus_8.bmp\n",
      "Processed: Ankylosaurus_9.bmp\n",
      "Processed: Ankylosaurus_10.bmp\n",
      "Processed: Ankylosaurus_11.bmp\n",
      "Processed: Ankylosaurus_12.bmp\n",
      "Processed: Ankylosaurus_13.bmp\n",
      "Processed: Ankylosaurus_14.bmp\n",
      "Processed: Ankylosaurus_15.bmp\n",
      "Processed: Ankylosaurus_16.bmp\n",
      "Processed: Ankylosaurus_17.bmp\n",
      "Processed: Ankylosaurus_18.bmp\n",
      "Processed: Ankylosaurus_19.bmp\n",
      "Processed: Ankylosaurus_20.bmp\n",
      "Processed: Ankylosaurus_21.bmp\n",
      "Processed: Ankylosaurus_22.bmp\n",
      "Processed: Ankylosaurus_23.bmp\n",
      "Processed: Ankylosaurus_24.bmp\n",
      "Processed: Ankylosaurus_25.bmp\n",
      "Processed: Ankylosaurus_26.bmp\n",
      "Processed: Ankylosaurus_27.bmp\n",
      "Processed: Ankylosaurus_28.bmp\n",
      "Processed: Ankylosaurus_29.bmp\n",
      "Processed: Ankylosaurus_30.bmp\n",
      "Processed: Ankylosaurus_31.bmp\n",
      "Processed: Ankylosaurus_32.bmp\n",
      "Processed: Ankylosaurus_33.bmp\n",
      "Processed: Ankylosaurus_34.bmp\n",
      "Processed: Ankylosaurus_35.bmp\n",
      "Processed: Ankylosaurus_36.bmp\n",
      "Processed: Ankylosaurus_37.bmp\n",
      "Processed: Ankylosaurus_38.bmp\n",
      "Processed: Ankylosaurus_39.bmp\n",
      "Processed: Ankylosaurus_40.bmp\n",
      "Processed: Ankylosaurus_41.bmp\n",
      "Processed: Ankylosaurus_42.bmp\n",
      "Processed: Ankylosaurus_43.bmp\n",
      "Processed: Ankylosaurus_44.bmp\n",
      "Processed: Ankylosaurus_45.bmp\n",
      "Processed: Ankylosaurus_46.bmp\n",
      "Processed: Ankylosaurus_47.bmp\n",
      "Processed: Ankylosaurus_48.bmp\n",
      "Processed: Ankylosaurus_49.bmp\n",
      "Processed: Ankylosaurus_50.bmp\n",
      "Processed: Ankylosaurus_51.bmp\n",
      "Processed: Ankylosaurus_52.bmp\n",
      "Processed: Ankylosaurus_53.bmp\n",
      "Processed: Ankylosaurus_54.bmp\n",
      "Processed: Ankylosaurus_55.bmp\n",
      "Processed: Ankylosaurus_56.bmp\n",
      "Processed: Ankylosaurus_57.bmp\n",
      "Processed: Ankylosaurus_58.bmp\n",
      "Processed: Ankylosaurus_59.bmp\n",
      "Processed: Ankylosaurus_60.bmp\n",
      "Processed: Ankylosaurus_61.bmp\n",
      "Processed: Ankylosaurus_62.bmp\n",
      "Processed: Ankylosaurus_63.bmp\n",
      "Processed: Ankylosaurus_64.bmp\n",
      "Processed: Ankylosaurus_65.bmp\n",
      "Processed: Ankylosaurus_66.bmp\n",
      "Processed: Ankylosaurus_67.bmp\n",
      "Processed: Ankylosaurus_68.bmp\n",
      "Processed: Ankylosaurus_69.bmp\n",
      "Processed: Ankylosaurus_70.bmp\n",
      "Processed: Ankylosaurus_71.bmp\n",
      "Processed: Ankylosaurus_72.bmp\n",
      "Processed: Ankylosaurus_73.bmp\n",
      "Processed: Ankylosaurus_74.bmp\n",
      "Processed: Ankylosaurus_75.bmp\n",
      "Processed: Ankylosaurus_76.bmp\n",
      "Processed: Ankylosaurus_77.bmp\n",
      "Processed: Ankylosaurus_78.bmp\n",
      "Processed: Ankylosaurus_79.bmp\n",
      "Processed: Ankylosaurus_80.bmp\n",
      "Processed: Ankylosaurus_81.bmp\n",
      "Processed: Ankylosaurus_82.bmp\n",
      "Processed: Ankylosaurus_83.bmp\n",
      "Processed: Ankylosaurus_84.bmp\n",
      "Processed: Ankylosaurus_85.bmp\n",
      "Processed: Ankylosaurus_86.bmp\n",
      "Processed: Ankylosaurus_87.bmp\n",
      "Processed: Ankylosaurus_88.bmp\n",
      "Processed: Ankylosaurus_89.bmp\n",
      "Processed: Ankylosaurus_90.bmp\n",
      "Processed: Ankylosaurus_91.bmp\n",
      "Processed: Ankylosaurus_92.bmp\n",
      "Processed: Ankylosaurus_93.bmp\n",
      "Processed: Ankylosaurus_94.bmp\n",
      "Processed: Ankylosaurus_95.bmp\n",
      "Processed: Ankylosaurus_96.bmp\n",
      "Processed: Ankylosaurus_97.bmp\n",
      "Processed: Ankylosaurus_98.bmp\n",
      "Processed: Ankylosaurus_99.bmp\n",
      "Finished processing folder: Ankylosaurus\n",
      "\n",
      "Processing folder: Baryonyx\n",
      "Processed: Baryonyx_0.bmp\n",
      "Processed: Baryonyx_1.bmp\n",
      "Processed: Baryonyx_2.bmp\n",
      "Processed: Baryonyx_3.bmp\n",
      "Processed: Baryonyx_4.bmp\n",
      "Processed: Baryonyx_5.bmp\n",
      "Processed: Baryonyx_6.bmp\n",
      "Processed: Baryonyx_7.bmp\n",
      "Processed: Baryonyx_8.bmp\n",
      "Processed: Baryonyx_9.bmp\n",
      "Processed: Baryonyx_10.bmp\n",
      "Processed: Baryonyx_11.bmp\n",
      "Processed: Baryonyx_12.bmp\n",
      "Processed: Baryonyx_13.bmp\n",
      "Processed: Baryonyx_14.bmp\n",
      "Processed: Baryonyx_15.bmp\n",
      "Processed: Baryonyx_16.bmp\n",
      "Processed: Baryonyx_17.bmp\n",
      "Processed: Baryonyx_18.bmp\n",
      "Processed: Baryonyx_19.bmp\n",
      "Processed: Baryonyx_20.bmp\n",
      "Processed: Baryonyx_21.bmp\n",
      "Processed: Baryonyx_22.bmp\n",
      "Processed: Baryonyx_23.bmp\n",
      "Processed: Baryonyx_24.bmp\n",
      "Processed: Baryonyx_25.bmp\n",
      "Processed: Baryonyx_26.bmp\n",
      "Processed: Baryonyx_27.bmp\n",
      "Processed: Baryonyx_28.bmp\n",
      "Processed: Baryonyx_29.bmp\n",
      "Processed: Baryonyx_30.bmp\n",
      "Processed: Baryonyx_31.bmp\n",
      "Processed: Baryonyx_32.bmp\n",
      "Processed: Baryonyx_33.bmp\n",
      "Processed: Baryonyx_34.bmp\n",
      "Processed: Baryonyx_35.bmp\n",
      "Processed: Baryonyx_36.bmp\n",
      "Processed: Baryonyx_37.bmp\n",
      "Processed: Baryonyx_38.bmp\n",
      "Processed: Baryonyx_39.bmp\n",
      "Processed: Baryonyx_40.bmp\n",
      "Processed: Baryonyx_41.bmp\n",
      "Processed: Baryonyx_42.bmp\n",
      "Processed: Baryonyx_43.bmp\n",
      "Processed: Baryonyx_44.bmp\n",
      "Processed: Baryonyx_45.bmp\n",
      "Processed: Baryonyx_46.bmp\n",
      "Processed: Baryonyx_47.bmp\n",
      "Processed: Baryonyx_48.bmp\n",
      "Processed: Baryonyx_49.bmp\n",
      "Processed: Baryonyx_50.bmp\n",
      "Processed: Baryonyx_51.bmp\n",
      "Processed: Baryonyx_52.bmp\n",
      "Processed: Baryonyx_53.bmp\n",
      "Processed: Baryonyx_54.bmp\n",
      "Processed: Baryonyx_55.bmp\n",
      "Processed: Baryonyx_56.bmp\n",
      "Processed: Baryonyx_57.bmp\n",
      "Processed: Baryonyx_58.bmp\n",
      "Processed: Baryonyx_59.bmp\n",
      "Processed: Baryonyx_60.bmp\n",
      "Processed: Baryonyx_61.bmp\n",
      "Processed: Baryonyx_62.bmp\n",
      "Processed: Baryonyx_63.bmp\n",
      "Processed: Baryonyx_64.bmp\n",
      "Processed: Baryonyx_65.bmp\n",
      "Processed: Baryonyx_66.bmp\n",
      "Processed: Baryonyx_67.bmp\n",
      "Processed: Baryonyx_68.bmp\n",
      "Processed: Baryonyx_69.bmp\n",
      "Processed: Baryonyx_70.bmp\n",
      "Processed: Baryonyx_71.bmp\n",
      "Processed: Baryonyx_72.bmp\n",
      "Processed: Baryonyx_73.bmp\n",
      "Processed: Baryonyx_74.bmp\n",
      "Processed: Baryonyx_75.bmp\n",
      "Processed: Baryonyx_76.bmp\n",
      "Processed: Baryonyx_77.bmp\n",
      "Processed: Baryonyx_78.bmp\n",
      "Processed: Baryonyx_79.bmp\n",
      "Processed: Baryonyx_80.bmp\n",
      "Processed: Baryonyx_81.bmp\n",
      "Processed: Baryonyx_82.bmp\n",
      "Processed: Baryonyx_83.bmp\n",
      "Processed: Baryonyx_84.bmp\n",
      "Processed: Baryonyx_85.bmp\n",
      "Processed: Baryonyx_86.bmp\n",
      "Processed: Baryonyx_87.bmp\n",
      "Processed: Baryonyx_88.bmp\n",
      "Processed: Baryonyx_89.bmp\n",
      "Processed: Baryonyx_90.bmp\n",
      "Processed: Baryonyx_91.bmp\n",
      "Processed: Baryonyx_92.bmp\n",
      "Processed: Baryonyx_93.bmp\n",
      "Processed: Baryonyx_94.bmp\n",
      "Processed: Baryonyx_95.bmp\n",
      "Processed: Baryonyx_96.bmp\n",
      "Processed: Baryonyx_97.bmp\n",
      "Processed: Baryonyx_98.bmp\n",
      "Processed: Baryonyx_99.bmp\n",
      "Finished processing folder: Baryonyx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process images in the 'dinosaurs' folder and save the processed images in a new folder\n",
    "process_images('dataset/dinosaurs', 'dataset/processed', max_subfolders=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image Processing Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No corrupted images found.\n"
     ]
    }
   ],
   "source": [
    "check_images_in_folder('dataset/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Allosaurus:\n",
      "  .bmp: 100\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Ankylosaurus:\n",
      "  .bmp: 100\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n",
      "\n",
      "Baryonyx:\n",
      "  .bmp: 100\n",
      "Succes: All images are present. \n",
      "Total: 100 images\n"
     ]
    }
   ],
   "source": [
    "counts = count_images_by_format('dataset/processed')\n",
    "\n",
    "for subfolder, formats in counts.items():\n",
    "    print(f\"\\n{subfolder}:\")\n",
    "    for format, count in formats.items():\n",
    "        print(f\"  {format}: {count}\")\n",
    "    total = sum(formats.values())\n",
    "    if total == 100:\n",
    "        print(f\"Succes: All images are present. \\nTotal: {total} images\")\n",
    "    else:\n",
    "        print(f\"Error: {total} images found, missing {100 - total} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_directory(directory):\n",
    "    \"\"\"\n",
    "    Clears the specified directory by removing all its contents.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the directory to be cleared.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    os.makedirs(directory)\n",
    "\n",
    "def split_dataset(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Split the images in the input folder into training and testing sets, and overwrite the images in the output folder.\n",
    "\n",
    "    Parameters:\n",
    "    input_folder (str): The path to the folder containing the input images.\n",
    "    output_folder (str): The path to the folder where the split images will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Clear the target directory\n",
    "    clear_directory(output_folder)\n",
    "\n",
    "    # Perform the split\n",
    "    splitfolders.ratio(input_folder, output=output_folder, seed=1337, ratio=(0.7, 0.1, 0.2), group_prefix=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting completed and target directories have been overwritten.\n"
     ]
    }
   ],
   "source": [
    "# Paths to the main folders\n",
    "processed_data_folder = \"dataset/processed\"\n",
    "\n",
    "# Output directories\n",
    "output_processed_split = \"dataset/split\"\n",
    "\n",
    "# Split processed data and overwrite\n",
    "split_dataset(processed_data_folder, output_processed_split)\n",
    "\n",
    "print(\"Data splitting completed and target directories have been overwritten.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of images in the split folders raw_split and processed_split\n",
    "def validate_split(input_folder, folder_name):\n",
    "    \"\"\"\n",
    "    Validate the split of images in the specified folder.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing the split images.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    print(\"-\"*10,folder_name,\"-\"*10)\n",
    "    for split in os.listdir(input_folder):\n",
    "        subfolder_path = os.path.join(input_folder, split)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            print(f\"\\n{split}:\")\n",
    "            counts = count_images_by_format(subfolder_path)\n",
    "            for subfolder, formats in counts.items():\n",
    "                print(f\"\\n{subfolder}:\")\n",
    "                for format, count in formats.items():\n",
    "                    print(f\"  {format}: {count}\")\n",
    "                total = sum(formats.values())\n",
    "                if \"train\" in subfolder_path and total == 70:\n",
    "                    print(f\"Succes: All images are present in training split \\nTotal: {total} images\")\n",
    "\n",
    "                elif \"test\" in subfolder_path and total == 20:\n",
    "                    print(f\"Succes: All images are present in testing split \\nTotal: {total} images\")\n",
    "\n",
    "                elif \"val\" in subfolder_path and total == 10:\n",
    "                    print(f\"Succes: All images are present in validation split \\nTotal: {total} images\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"Error: {total} images found, split not balanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Processed Split ----------\n",
      "\n",
      "test:\n",
      "\n",
      "Allosaurus:\n",
      "  .bmp: 20\n",
      "Succes: All images are present in testing split \n",
      "Total: 20 images\n",
      "\n",
      "Ankylosaurus:\n",
      "  .bmp: 20\n",
      "Succes: All images are present in testing split \n",
      "Total: 20 images\n",
      "\n",
      "Baryonyx:\n",
      "  .bmp: 20\n",
      "Succes: All images are present in testing split \n",
      "Total: 20 images\n",
      "\n",
      "train:\n",
      "\n",
      "Allosaurus:\n",
      "  .bmp: 70\n",
      "Succes: All images are present in training split \n",
      "Total: 70 images\n",
      "\n",
      "Ankylosaurus:\n",
      "  .bmp: 70\n",
      "Succes: All images are present in training split \n",
      "Total: 70 images\n",
      "\n",
      "Baryonyx:\n",
      "  .bmp: 70\n",
      "Succes: All images are present in training split \n",
      "Total: 70 images\n",
      "\n",
      "val:\n",
      "\n",
      "Allosaurus:\n",
      "  .bmp: 10\n",
      "Succes: All images are present in validation split \n",
      "Total: 10 images\n",
      "\n",
      "Ankylosaurus:\n",
      "  .bmp: 10\n",
      "Succes: All images are present in validation split \n",
      "Total: 10 images\n",
      "\n",
      "Baryonyx:\n",
      "  .bmp: 10\n",
      "Succes: All images are present in validation split \n",
      "Total: 10 images\n",
      "\n",
      "\n",
      "\n",
      "No corrupted images found.\n"
     ]
    }
   ],
   "source": [
    "# Validate the split of images in the processed_split folder\n",
    "validate_split(output_processed_split, \"Processed Split\")\n",
    "print(\"\\n\\n\")\n",
    "check_images_in_folder(output_processed_split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
